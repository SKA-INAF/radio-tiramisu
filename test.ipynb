{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiramisu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# ## Dependencies\n",
    "# In[1]:\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import tiramisu\n",
    "from datasets import camvid\n",
    "from datasets import joint_transforms\n",
    "import utils.imgs\n",
    "import utils.training as train_utils\n",
    "import datetime\n",
    "from IPython.display import Image, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/')\n",
    "RESULTS_PATH = Path('./output/')\n",
    "WEIGHTS_PATH = Path('./weights/')\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "WEIGHTS_PATH.mkdir(exist_ok=True)\n",
    "batch_size=20\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=camvid.mean, std=camvid.std)\n",
    "\n",
    "test_dset = camvid.CamVid(\n",
    "    DATA_PATH, 'test', joint_transform=None,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize([132, 132]),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    target_transform=transforms.Compose([          \n",
    "          camvid.LabelToLongTensor(),\n",
    "    ]))\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=batch_size, shuffle=False)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tiramisu.FCDenseNet67(n_classes=4).cpu()\n",
    "model.apply(train_utils.weights_init)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "criterion = nn.NLLLoss(weight=camvid.class_weight.cpu()).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utils.load_weights(model, str(WEIGHTS_PATH)+'/latest.th')\n",
    "train_utils.test(model, test_loader, criterion, epoch=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute segmentation for the images in \"output folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utils.view_sample_predictions(model, test_loader, 0, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "listOfImageNames = [\"output/\"+f for f in os.listdir('./output') if(\".png\" in f)]\n",
    "\n",
    "for imageName in listOfImageNames:\n",
    "    display(Image(filename=imageName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
